{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Input\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.models import Model\n",
    "from keras.layers import GlobalAveragePooling2D,MaxPooling2D\n",
    "from keras.layers import Dense,Flatten,SpatialDropout2D\n",
    "from keras.layers.merge import concatenate\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.callbacks import History\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "image_size = (64, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_model_history(history):\n",
    "    \"\"\"\n",
    "    Function to plot training and validation data of model\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    history: dictionary\n",
    "             history of training and validation of model\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \n",
    "    \"\"\"\n",
    "    print(history.history.keys())\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['acc'])\n",
    "    plt.plot(history.history['val_acc'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildNet(num_classes):\n",
    "    \"\"\"\n",
    "    Function to build 4 layer NN with 2 Conv layers, 1 MaxPool layer,\n",
    "    1 GlobalMaxPool layer and 2 Dense layers\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    num_classes: int\n",
    "                 Number of classes in training data\n",
    "    Returns\n",
    "    -------\n",
    "    Neural Network created\n",
    "    \"\"\"\n",
    "    model1=Sequential()\n",
    "    model1.add(Convolution2D(32, (3,3),input_shape=(image_size[0], image_size[1], 3),activation='relu'))\n",
    "    model1.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model1.add(Convolution2D(64,(3,3),activation='relu'))\n",
    "    model1.add(GlobalAveragePooling2D())\n",
    "\n",
    "    model1.add(Dense(128, activation='relu'))\n",
    "    model1.add(Dense(1, activation='sigmoid'))\n",
    "    model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model1.summary())\n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainNet(training_set, validation_set):\n",
    "    \"\"\"\n",
    "    Function to train Neural Network Created, save it as hd5 and plot the various parameters.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    training_set:   ImageDataGenerator object\n",
    "                    Training set with labels.\n",
    "    validation_set: ImageDataGenerator object\n",
    "                    Validation set with labels.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    history: dictionary\n",
    "             History of training and validation of model.\n",
    "    \"\"\"\n",
    "    num_classes = 1#y_train.shape[1]\n",
    "    model = buildNet(num_classes)\n",
    "    history = History()\n",
    "    callbacks = [EarlyStopping(monitor='val_loss', patience=5),\n",
    "             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True),history]\n",
    "    \n",
    "    history = model.fit_generator(training_set,\n",
    "                                steps_per_epoch = 8000/32,\n",
    "                                epochs = 15,\n",
    "                                validation_data = validation_set,\n",
    "                                validation_steps = 64,\n",
    "                                workers = 8)\n",
    "    model.save('model.hd5')\n",
    "    plot_model_history(history)\n",
    "\n",
    "    #model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=30, batch_size=100,callbacks=callbacks,verbose=1)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1485 images belonging to 2 classes.\n",
      "Found 413 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('E:/Data/ML DATASETS/retin_data/cimages_train/',\n",
    "                                                 target_size = image_size,\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "validation_set = test_datagen.flow_from_directory('E:/Data/ML DATASETS/retin_data/cimages_test',\n",
    "                                                  target_size = image_size,\n",
    "                                                  batch_size = 32,\n",
    "                                                  class_mode = 'binary', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From G:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From G:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "mod=load_model('model.hd5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mod.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_gen = ImageDataGenerator(rescale = 1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# PROJECT_PATH = os.path.abspath(os.path.dirname(__file__))\n",
    "# CAPTHA_ROOT = os.path.join(PROJECT_PATH,'')\n",
    "    \n",
    "test_data = test_gen.flow_from_directory('C:/Users/keval/Desktop/Machine Learning/ML Projects/Diabetic Retinopathy/My Diabetic Retinopathy/symp',\n",
    "                                              target_size = (64, 64),\n",
    "                                              batch_size = 32,\n",
    "                                              class_mode = 'binary', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = test_data.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "<keras_preprocessing.image.directory_iterator.DirectoryIterator object at 0x000001FC40C254E0>\n"
     ]
    }
   ],
   "source": [
    "nb_samples = len(filenames)\n",
    "print(nb_samples)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = mod.predict_generator(test_data,steps = nb_samples/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss, acc = mod.evaluate_generator(test_data, steps=nb_samples/32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS:  1.2418220043182373\n",
      "ACC:  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"LOSS: \", loss)\n",
    "print(\"ACC: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict[0][0] > 0.4\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.57\n"
     ]
    }
   ],
   "source": [
    "percent_chance = round(predict[0][0]*100, 2)\n",
    "print(percent_chance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "test_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]]\n",
      "lksdfjjjjjjjjjjjjjjjjjjjjjjjjjjjjj\n",
      "[[[0 0 0]\n",
      "  [1 1 1]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 2 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [1 1 1]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]\n",
      "\n",
      " [[0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  ...\n",
      "  [0 0 0]\n",
      "  [0 0 0]\n",
      "  [0 0 0]]]\n",
      "[[[[0.         0.         0.        ]\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.00784314 0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.00392157 0.00392157 0.00392157]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]\n",
      "   [0.         0.         0.        ]]]]\n",
      "<keras.engine.sequential.Sequential object at 0x0000022F806EBC18>\n",
      "------------\n",
      "Diabetic\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# dimensions of our images    -----   are these then grayscale (black and white)?\n",
    "img_width, img_height = 64, 64\n",
    "\n",
    "# load the model we saved\n",
    "model = load_model('model.hd5')\n",
    "\n",
    "# # Get test image ready\n",
    "# test_image = image.load_img('E:/Data/ML DATASETS/retin_data/cimages_val/symptoms/10822_right.jpeg', target_size=(64, 64))\n",
    "# test_image = image.img_to_array(test_image)\n",
    "# test_image = np.expand_dims(test_image, axis=0)\n",
    "# test_image_2 = image.load_img('C:/Users/keval/Desktop/Machine Learning/ML Projects/Dataset Samples/DR/symp/1540_right.jpeg', target_size=(64, 64))\n",
    "# test_image_2 = image.img_to_array(test_image_2)\n",
    "# test_image_2 = np.expand_dims(test_image_2, axis=0)\n",
    "\n",
    "# # test_image = test_image.reshape(img_width, img_height*3)    # Ambiguity!\n",
    "# test_image = test_image.reshape(1, img_width, img_height, 3)\n",
    "# test_image_2 = test_image_2.reshape(1, img_width, img_height, 3)\n",
    "\n",
    "# mult_images = np.vstack([test_image, test_image_2])\n",
    "\n",
    "# result = model.predict(test_image, batch_size=1)\n",
    "# print(result)\n",
    "\n",
    "# import argparse\n",
    "# import random\n",
    "# import cv2\n",
    "# from keras.preprocessing.image import img_to_array\n",
    "\n",
    "# orig = cv2.imread('E:/Data/ML DATASETS/retin_data/cimages_val/nosymptoms/13400_right.jpeg')\n",
    "# print(orig)\n",
    "# print('lksdfjjjjjjjjjjjjjjjjjjjjjjjjjjjjj')\n",
    "# image = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB)\n",
    "# image = cv2.resize(image, (64, 64))\n",
    "# print(image)\n",
    "# image = image.astype(\"float\") / 255.0\n",
    "# image = img_to_array(image)\n",
    "# image = np.expand_dims(image, axis=0)\n",
    "# print(image)\n",
    "# print(model)\n",
    "# print('------------')\n",
    "\n",
    "# pred = model.predict(image)\n",
    "# pred = pred.argmax(axis=1)[0]\n",
    "\n",
    "# label = \"Diabetic\" if pred == 0 else \"Non Diabetic\"\n",
    "# color = (0, 0, 255) if pred == 0 else (0, 255, 0)\n",
    "\n",
    "# print(label)\n",
    "\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# PROJECT_PATH = os.path.abspath(os.path.dirname(__file__))\n",
    "# CAPTHA_ROOT = os.path.join(PROJECT_PATH,'')\n",
    "    \n",
    "test_data_2 = test_gen.flow_from_directory('C:/Users/keval/Desktop/Machine Learning/ML Projects/Diabetic Retinopathy/My Diabetic Retinopathy/nonsymp',\n",
    "                                              target_size = (64, 64),\n",
    "                                              batch_size = 32,\n",
    "                                              class_mode = 'binary', shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filenames = test_data_2.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "nb_samples = len(filenames)\n",
    "print(nb_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = mod.predict_generator(test_data_2,steps = nb_samples/32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.1398253],\n",
       "       [0.1196612]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss, acc = mod.evaluate_generator(test_data, steps=nb_samples/32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS:  1.2418220043182373\n",
      "ACC:  0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"LOSS: \", loss)\n",
    "print(\"ACC: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict[0][0] > 0.4\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.98\n"
     ]
    }
   ],
   "source": [
    "percent_chance = round(predict[0][0]*100, 2)\n",
    "print(percent_chance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
